<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>hyperspy.misc.machine_learning package &mdash; Hyperspy 0.7b1 documentation</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.7b1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/sidebar.js"></script>
    <link rel="shortcut icon" href="../_static/hyperspy_logo.ico"/>
    <link rel="top" title="Hyperspy 0.7b1 documentation" href="../index.html" />
 
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-25260850-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../index.html">Hyperspy 0.7b1 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="hyperspy-misc-machine-learning-package">
<h1>hyperspy.misc.machine_learning package<a class="headerlink" href="#hyperspy-misc-machine-learning-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-hyperspy.misc.machine_learning.fastica">
<span id="hyperspy-misc-machine-learning-fastica-module"></span><h2>hyperspy.misc.machine_learning.fastica module<a class="headerlink" href="#module-hyperspy.misc.machine_learning.fastica" title="Permalink to this headline">¶</a></h2>
<p>Python implementation of the fast ICA algorithms.</p>
<p>Reference: Tables 8.3 and 8.4 page 196 in the book:
Independent Component Analysis, by  Hyvarinen et al.</p>
<dl class="function">
<dt id="hyperspy.misc.machine_learning.fastica.fastica">
<tt class="descclassname">hyperspy.misc.machine_learning.fastica.</tt><tt class="descname">fastica</tt><big>(</big><em>X</em>, <em>n_components=None</em>, <em>algorithm='parallel'</em>, <em>whiten=True</em>, <em>fun='logcosh'</em>, <em>fun_prime=''</em>, <em>fun_args={}</em>, <em>max_iter=200</em>, <em>tol=0.0001</em>, <em>w_init=None</em>, <em>random_state=None</em><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.fastica.fastica" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform Fast Independent Component Analysis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training vector, where n_samples is the number of samples and
n_features is the number of features.</p>
</div></blockquote>
<p><strong>n_components</strong> : int, optional</p>
<blockquote>
<div><p>Number of components to extract. If None no dimension reduction
is performed.</p>
</div></blockquote>
<p><strong>algorithm</strong> : {&#8216;parallel&#8217;, &#8216;deflation&#8217;}, optional</p>
<blockquote>
<div><p>Apply a parallel or deflational FASTICA algorithm.</p>
</div></blockquote>
<p><strong>whiten: boolean, optional</strong> :</p>
<blockquote>
<div><p>If True perform an initial whitening of the data.
If False, the data is assumed to have already been
preprocessed: it should be centered, normed and white.
Otherwise you will get incorrect results.
In this case the parameter n_components will be ignored.</p>
</div></blockquote>
<p><strong>fun</strong> : string or function, optional</p>
<blockquote>
<div><p>The functional form of the G function used in the
approximation to neg-entropy. Could be either &#8216;logcosh&#8217;, &#8216;exp&#8217;,
or &#8216;cube&#8217;.
You can also provide your own function but in this case, its
derivative should be provided via argument fun_prime</p>
</div></blockquote>
<p><strong>fun_prime</strong> : empty string (&#8216;&#8217;) or function, optional</p>
<blockquote>
<div><p>See fun.</p>
</div></blockquote>
<p><strong>fun_args: dictionary, optional</strong> :</p>
<blockquote>
<div><p>If empty and if fun=&#8217;logcosh&#8217;, fun_args will take value
{&#8216;alpha&#8217; : 1.0}</p>
</div></blockquote>
<p><strong>max_iter: int, optional</strong> :</p>
<blockquote>
<div><p>Maximum number of iterations to perform</p>
</div></blockquote>
<p><strong>tol: float, optional</strong> :</p>
<blockquote>
<div><p>A positive scalar giving the tolerance at which the
un-mixing matrix is considered to have converged</p>
</div></blockquote>
<p><strong>w_init: (n_components, n_components) array, optional</strong> :</p>
<blockquote>
<div><p>Initial un-mixing array of dimension (n.comp,n.comp).
If None (default) then an array of normal r.v.&#8217;s is used</p>
</div></blockquote>
<p><strong>source_only: boolean, optional</strong> :</p>
<blockquote>
<div><p>if True, only the sources matrix is returned</p>
</div></blockquote>
<p><strong>random_state: int or RandomState</strong> :</p>
<blockquote>
<div><p>Pseudo number generator state used for random sampling.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>K: (n_components, p) array or None.</strong> :</p>
<blockquote>
<div><p>If whiten is &#8216;True&#8217;, K is the pre-whitening matrix that projects data
onto the first n.comp principal components. If whiten is &#8216;False&#8217;, K is
&#8216;None&#8217;.</p>
</div></blockquote>
<p><strong>W: (n_components, n_components) array</strong> :</p>
<blockquote>
<div><p>estimated un-mixing matrix
The mixing matrix can be obtained by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">I</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>S: (n_components, n) array</strong> :</p>
<blockquote class="last">
<div><p>estimated source matrix</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The data matrix X is considered to be a linear combination of
non-Gaussian (independent) components i.e. X = AS where columns of S
contain the independent components and A is a linear mixing
matrix. In short ICA attempts to <cite>un-mix&#8217; the data by estimating an
un-mixing matrix W where ``S = W K X.`</cite></p>
<p>This implementation was originally made for data of shape
[n_features, n_samples]. Now the input is transposed
before the algorithm is applied. This makes it slightly
faster for Fortran-ordered input.</p>
<p>Implemented using FastICA:
<cite>A. Hyvarinen and E. Oja, Independent Component Analysis:
Algorithms and Applications, Neural Networks, 13(4-5), 2000,
pp. 411-430</cite></p>
</dd></dl>

<dl class="class">
<dt id="hyperspy.misc.machine_learning.fastica.FastICA">
<em class="property">class </em><tt class="descclassname">hyperspy.misc.machine_learning.fastica.</tt><tt class="descname">FastICA</tt><big>(</big><em>n_components=None</em>, <em>algorithm='parallel'</em>, <em>whiten=True</em>, <em>fun='logcosh'</em>, <em>fun_prime=''</em>, <em>fun_args=None</em>, <em>max_iter=200</em>, <em>tol=0.0001</em>, <em>w_init=None</em>, <em>random_state=None</em><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.fastica.FastICA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">hyperspy.misc.machine_learning.fastica.BaseEstimator</span></tt></p>
<p>FastICA; a fast algorithm for Independent Component Analysis</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>n_components</strong> : int, optional</p>
<blockquote>
<div><p>Number of components to use. If none is passed, all are used.</p>
</div></blockquote>
<p><strong>algorithm</strong> : {&#8216;parallel&#8217;, &#8216;deflation&#8217;}</p>
<blockquote>
<div><p>Apply parallel or deflational algorithm for FastICA</p>
</div></blockquote>
<p><strong>whiten</strong> : boolean, optional</p>
<blockquote>
<div><p>If whiten is false, the data is already considered to be
whitened, and no whitening is performed.</p>
</div></blockquote>
<p><strong>fun</strong> : {&#8216;logcosh&#8217;, &#8216;exp&#8217;, or &#8216;cube&#8217;}, or a callable</p>
<blockquote>
<div><p>The non-linear function used in the FastICA loop to approximate
negentropy. If a function is passed, it derivative should be
passed as the &#8216;fun_prime&#8217; argument.</p>
</div></blockquote>
<p><strong>fun_prime</strong> : None or a callable</p>
<blockquote>
<div><p>The derivative of the non-linearity used.</p>
</div></blockquote>
<p><strong>max_iter</strong> : int, optional</p>
<blockquote>
<div><p>Maximum number of iterations during fit</p>
</div></blockquote>
<p><strong>tol</strong> : float, optional</p>
<blockquote>
<div><p>Tolerance on update at each iteration</p>
</div></blockquote>
<p><strong>w_init</strong> : None of an (n_components, n_components) ndarray</p>
<blockquote>
<div><p>The mixing matrix to be used to initialize the algorithm.</p>
</div></blockquote>
<p><strong>random_state: int or RandomState</strong> :</p>
<blockquote class="last">
<div><p>Pseudo number generator state used for random sampling.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Implementation based on
<cite>A. Hyvarinen and E. Oja, Independent Component Analysis:
Algorithms and Applications, Neural Networks, 13(4-5), 2000,
pp. 411-430</cite></p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="49%" />
<col width="26%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>unmixing_matrix_</cite></td>
<td>2D array, [n_components, n_samples]</td>
<td>The unmixing matrix</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#hyperspy.misc.machine_learning.fastica.FastICA.fit" title="hyperspy.misc.machine_learning.fastica.FastICA.fit"><tt class="xref py py-obj docutils literal"><span class="pre">fit</span></tt></a>(X)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#hyperspy.misc.machine_learning.fastica.FastICA.get_mixing_matrix" title="hyperspy.misc.machine_learning.fastica.FastICA.get_mixing_matrix"><tt class="xref py py-obj docutils literal"><span class="pre">get_mixing_matrix</span></tt></a>()</td>
<td>Compute the mixing matrix</td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">get_params</span></tt>([deep])</td>
<td>Get parameters for the estimator</td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">set_params</span></tt>(**params)</td>
<td>Set the parameters of the estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#hyperspy.misc.machine_learning.fastica.FastICA.transform" title="hyperspy.misc.machine_learning.fastica.FastICA.transform"><tt class="xref py py-obj docutils literal"><span class="pre">transform</span></tt></a>(X)</td>
<td>Apply un-mixing matrix &#8220;W&#8221; to X to recover the sources</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="hyperspy.misc.machine_learning.fastica.FastICA.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.fastica.FastICA.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="hyperspy.misc.machine_learning.fastica.FastICA.get_mixing_matrix">
<tt class="descname">get_mixing_matrix</tt><big>(</big><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.fastica.FastICA.get_mixing_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the mixing matrix</p>
</dd></dl>

<dl class="method">
<dt id="hyperspy.misc.machine_learning.fastica.FastICA.transform">
<tt class="descname">transform</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.fastica.FastICA.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply un-mixing matrix &#8220;W&#8221; to X to recover the sources</p>
<p>S = X * W.T</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-hyperspy.misc.machine_learning.import_sklearn">
<span id="hyperspy-misc-machine-learning-import-sklearn-module"></span><h2>hyperspy.misc.machine_learning.import_sklearn module<a class="headerlink" href="#module-hyperspy.misc.machine_learning.import_sklearn" title="Permalink to this headline">¶</a></h2>
<p>Import sklearn, fast_svd and randomized_svd from scikits-learn
with support for multiple versions</p>
</div>
<div class="section" id="module-hyperspy.misc.machine_learning.orthomax">
<span id="hyperspy-misc-machine-learning-orthomax-module"></span><h2>hyperspy.misc.machine_learning.orthomax module<a class="headerlink" href="#module-hyperspy.misc.machine_learning.orthomax" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="hyperspy.misc.machine_learning.orthomax.orthomax">
<tt class="descclassname">hyperspy.misc.machine_learning.orthomax.</tt><tt class="descname">orthomax</tt><big>(</big><em>A</em>, <em>gamma=1</em>, <em>reltol=1.4901e-07</em>, <em>maxit=256</em><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.orthomax.orthomax" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-hyperspy.misc.machine_learning.tools">
<span id="hyperspy-misc-machine-learning-tools-module"></span><h2>hyperspy.misc.machine_learning.tools module<a class="headerlink" href="#module-hyperspy.misc.machine_learning.tools" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="hyperspy.misc.machine_learning.tools.amari">
<tt class="descclassname">hyperspy.misc.machine_learning.tools.</tt><tt class="descname">amari</tt><big>(</big><em>C</em>, <em>A</em><big>)</big><a class="headerlink" href="#hyperspy.misc.machine_learning.tools.amari" title="Permalink to this definition">¶</a></dt>
<dd><p>Amari test for ICA
Adapted from the MILCA package <a class="reference external" href="http://www.klab.caltech.edu/~kraskov/MILCA/">http://www.klab.caltech.edu/~kraskov/MILCA/</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>C</strong> : numpy array</p>
<p class="last"><strong>A</strong> : numpy array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-hyperspy.misc.machine_learning">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-hyperspy.misc.machine_learning" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/hyperspy_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">hyperspy.misc.machine_learning package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-hyperspy.misc.machine_learning.fastica">hyperspy.misc.machine_learning.fastica module</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-hyperspy.misc.machine_learning.import_sklearn">hyperspy.misc.machine_learning.import_sklearn module</a></li>
<li><a class="reference internal" href="#module-hyperspy.misc.machine_learning.orthomax">hyperspy.misc.machine_learning.orthomax module</a></li>
<li><a class="reference internal" href="#module-hyperspy.misc.machine_learning.tools">hyperspy.misc.machine_learning.tools module</a></li>
<li><a class="reference internal" href="#module-hyperspy.misc.machine_learning">Module contents</a></li>
</ul>
</li>
</ul>

  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/api/hyperspy.misc.machine_learning.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../index.html">Hyperspy 0.7b1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2012, The Hyperspy development team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b2.
    </div>
  </body>
</html>